{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ElasticSearch.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e092ffcd-1a0e-4063-94e5-fc2fd9fdfdd2"
      },
      "source": [
        "#ADM_Assignment3_Team3"
      ],
      "id": "e092ffcd-1a0e-4063-94e5-fc2fd9fdfdd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9244ef3-0d82-48be-baf2-f4bf337afbf1"
      },
      "source": [
        "#Indexing data to query Elasticsearch for similar images"
      ],
      "id": "f9244ef3-0d82-48be-baf2-f4bf337afbf1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08faf363-8423-4b7e-b33e-513a141d7640"
      },
      "source": [
        ""
      ],
      "id": "08faf363-8423-4b7e-b33e-513a141d7640",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edc48a39-296f-4965-9baa-e4eb1aed7ec5"
      },
      "source": [
        ""
      ],
      "id": "edc48a39-296f-4965-9baa-e4eb1aed7ec5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "959162c9-b084-40c8-b152-92ef594890af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "e128d3ff-a43b-497b-d9aa-194ae42fbc7f"
      },
      "source": [
        "import json\n",
        "\n",
        "# import time for its sleep method\n",
        "from time import sleep\n",
        "\n",
        "# import the datetime libraries datetime.now() method\n",
        "from datetime import datetime\n",
        "\n",
        "# use the elasticsearch client's helpers class for _bulk API\n",
        "from elasticsearch import Elasticsearch, helpers"
      ],
      "id": "959162c9-b084-40c8-b152-92ef594890af",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d554a05a2484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# use the elasticsearch client's helpers class for _bulk API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0melasticsearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elasticsearch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3e5a4e5-760c-4326-8618-febd5833c129"
      },
      "source": [
        "# declare a client instance of the Python Elasticsearch library\n",
        "client = Elasticsearch(\"localhost:9200\")"
      ],
      "id": "a3e5a4e5-760c-4326-8618-febd5833c129",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2e5717a-b4ea-4f10-b581-fe4c67cffdcb",
        "outputId": "36999938-2fc6-45fc-f088-4c8549c1840c"
      },
      "source": [
        "\n",
        "# define a function that will load a text file\n",
        "def get_data_from_text_file(self):\n",
        "# the function will return a list of docs\n",
        "    return [l.strip() for l in open(str(self), encoding=\"utf8\", errors='ignore')]\n",
        "\n",
        "# call the function to get the string data containing docs\n",
        "docs = get_data_from_text_file(\"nearest_neighbours_json.json\")\n",
        "\n",
        "# print the length of the documents in the string\n",
        "print (\"String docs length:\", len(docs))"
      ],
      "id": "b2e5717a-b4ea-4f10-b581-fe4c67cffdcb",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "String docs length: 132914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d15b61ca-9108-43c4-b1df-7165ae618e7f",
        "outputId": "e4bbc755-2c79-4322-d8af-135c30555ab8"
      },
      "source": [
        "import json\n",
        " \n",
        "from tqdm import tqdm\n",
        " \n",
        "from elasticsearch import Elasticsearch\n",
        " \n",
        "es = Elasticsearch(\"localhost:9200\")\n",
        " \n",
        "def main():\n",
        "    skus = json.load(open('/Users/harooniqbal/Desktop/new/NEU_SushmithaJogula/Semester3/ADM/Assignment3/nearest_neighbours_json.json'))\n",
        "    payload = []\n",
        "    for sku in tqdm(skus):\n",
        "        payload.append(json.dumps({'index': {}}))\n",
        "        payload.append(json.dumps(sku))\n",
        "    es.bulk('\\n'.join(payload), index='yg-vs-es-index', doc_type='_doc')\n",
        "    es.indices.refresh(index='yg-vs-es-index')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "id": "d15b61ca-9108-43c4-b1df-7165ae618e7f",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5112/5112 [00:00<00:00, 57550.60it/s]\n",
            "<ipython-input-11-56bedffc2093>:15: DeprecationWarning: Using positional arguments for APIs is deprecated and will be disabled in 8.0.0. Instead use only keyword arguments for all APIs. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
            "  es.bulk('\\n'.join(payload), index='yg-vs-es-index', doc_type='_doc')\n",
            "/Users/harooniqbal/opt/anaconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py:209: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\n",
            "  warnings.warn(message, category=ElasticsearchWarning)\n",
            "/Users/harooniqbal/opt/anaconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py:209: ElasticsearchWarning: [types removal] Specifying types in bulk requests is deprecated.\n",
            "  warnings.warn(message, category=ElasticsearchWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8062b9af-07d0-4972-8ea7-8c6f1ea73c1e"
      },
      "source": [
        "import base64\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# image_vec from image_src\n",
        "def get_vector_from_source(image_src):\n",
        "    tfs_endpoint = 'http://127.0.0.1/bd/v1/models/slim_inception_resnet_v2:predict'\n",
        "  # image_str = requests.get(image_src).content\n",
        "    image_str = open(image_src, 'rb').read()\n",
        "    image_b64 = base64.b64encode(image_str).decode('utf-8')\n",
        "    signature = dict(\n",
        "        signature_name='omnium',\n",
        "        instances=list([\n",
        "            dict(\n",
        "                    images=dict(\n",
        "                    b64=image_b64\n",
        "        )\n",
        "      )\n",
        "    ])\n",
        "  )\n",
        "    responses = requests.post(\n",
        "    tfs_endpoint, json=signature\n",
        "  )\n",
        "    image_vec = responses.json().get('predictions', list([dict()]))[0].get('vector')\n",
        "    return image_vec\n",
        "\n",
        "# image_tkn from image_vec\n",
        "def get_sign(x):\n",
        "    if x >= 0:\n",
        "        return '+'\n",
        "    else:\n",
        "        return '-'\n",
        "\n",
        "def get_tokens_from_vector_sign(vector, n=256):\n",
        "    assert vector is not None and n != 0, 'Invalid vector, or n.'\n",
        "    tokens = [\n",
        "        'i{index}v{value}'.format(\n",
        "          index=i, value=get_sign(vector[i])\n",
        "        )for i in np.argpartition(\n",
        "      np.abs(vector), -n)[-n:]\n",
        "  ]\n",
        "    return tokens\n",
        "\n",
        "def get_tokens_from_vector_round(vector, n=256, ndigits=0):\n",
        "    assert vector is not None and n != 0 and ndigits >= -1, 'Invalid vector, n, or ndigits.'\n",
        "    if ndigits == -1:\n",
        "        return get_tokens_from_vector_sign(vector, n)\n",
        "    tokens = [\n",
        "    'i{index}v{value}'.format(\n",
        "      index=i, value=round(vector[i], ndigits)\n",
        "    )for i in np.argpartition(\n",
        "      np.abs(vector), -n)[-n:]\n",
        "  ]\n",
        "    return tokens\n",
        "\n",
        "def get_vecstr_from_vector(vector, precision=4):\n",
        "    return ' '.join([str(round(v, precision)) for v in vector])\n",
        "\n",
        "# main\n",
        "def main():\n",
        "    skus = json.load(open('./skus_insitu.json'))\n",
        "    for sku in tqdm(skus):\n",
        "        image_vec = get_vector_from_source(sku['image_src'].replace('http://127.0.0.1/images', './assets/insitu'))\n",
        "        if image_vec is not None:\n",
        "            sku['image_vec'] = get_vecstr_from_vector(image_vec)\n",
        "            sku['image_tkn'] = get_tokens_from_vector_sign(image_vec)\n",
        "        else:\n",
        "            print('Invalid im2vec: {}'.format(sku['image_src']))\n",
        "    with open('./skus_insitu_im2vec.json', 'w') as fp:\n",
        "        json.dump(skus, fp)\n",
        "    skus = json.load(open('./skus_onsite.json'))\n",
        "    for sku in tqdm(skus):\n",
        "        image_vec = get_vector_from_source(sku['image_src'].replace('http://127.0.0.1/images', './assets/onsite'))\n",
        "        if image_vec is not None:\n",
        "            sku['image_vec'] = get_vecstr_from_vector(image_vec)\n",
        "            sku['image_tkn'] = get_tokens_from_vector_sign(image_vec)\n",
        "        else:\n",
        "            print('Invalid im2vec: {}'.format(sku['image_src']))\n",
        "    with open('./skus_onsite_im2vec.json', 'w') as fp:\n",
        "        json.dump(skus, fp)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "id": "8062b9af-07d0-4972-8ea7-8c6f1ea73c1e",
      "execution_count": null,
      "outputs": []
    }
  ]
}